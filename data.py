import os, sys
from tqdm import tqdm
import pickle
import pandas as pd
import numpy as np
from sklearn.utils import shuffle
from config import *

# np.set_printoptions(threshold=sys.maxsize)
LABEL_LIST = ["Control", "Autism", "Aspergers"]
INS_LIST = ['YALE', 'KKI', 'UCLA_1', 'UCLA_2', 'PITT', 'OLIN', 'SDSU', 'TRINITY', 'UM_1', 'UM_2', 'USM', 'CMU', 'LEUVEN_1', 'LEUVEN_2', 'NYU', 'MAX_MUN', 'CALTECH', 'SBL']
GENDER_LIST = [1, 2]


def map_to_onehot(value, all_values):
    """
    Convert left table entry to one hot vector.
    value: a table entry, i.e., the content in a cell of the table. E.g. "Autism" in LABEL_LIST
    all_values: all possible values that could appear in a column. E.g. LABEL_LIST
    """
    idx = all_values.index(value)
    l = len(all_values)
    one_hot = [0.,] * idx + [1.,] + [0.] * (l - idx - 1)
    return one_hot

def preprocess(A, threshold):
    """
    Preprocess an input matrix.
    A: adjacency matrix
    threshold: convert edge weights to connectivity, i.e., when edge weight is
            larger than the threshold, the edge is considered to be connecting
            its two corresponding nodes.
    """
    X = A.copy()
    # A[X <= threshold] = 0.
    # A[X > threshold] = 1.
    return A, X

def upsample(graphs, genders, inss, ages, Y):
    """
    Upsample the dataset so that it is balanced.
    (Each class has the same number of data points/examples)
    """
    class_dist = np.sum(Y, axis = 0)
    class_max_size = int(np.max(class_dist))
    graphs_upsampled, genders_upsampled, inss_upsampled, ages_upsampled, Y_upsampled = \
        np.copy(graphs), np.copy(genders), np.copy(inss), np.copy(ages), np.copy(Y)
    for which_class in range(class_dist.shape[0]):
        upsample_size = int(class_max_size - class_dist[which_class])
        if upsample_size > 0:
            class_idx = np.where(np.argmax(Y, axis = 1) == which_class)[0]
            upsampled_class_idx = np.random.choice(class_idx, size=upsample_size, replace=True)
            graphs_upsampled = np.concatenate((graphs_upsampled, graphs[upsampled_class_idx]), axis = 0)
            genders_upsampled = np.concatenate((genders_upsampled, genders[upsampled_class_idx]), axis = 0)
            inss_upsampled = np.concatenate((inss_upsampled, inss[upsampled_class_idx]), axis = 0)
            ages_upsampled = np.concatenate((ages_upsampled, ages[upsampled_class_idx]), axis = 0)
            Y_upsampled = np.concatenate((Y_upsampled, Y[upsampled_class_idx]), axis = 0)

    #         print(graphs_upsampled.shape)
    #         print(genders_upsampled.shape)
    #         print(inss_upsampled.shape)
    #         print(ages_upsampled.shape)
    #         print(Y_upsampled.shape)
    #         print(upsampled_class_idx.shape)
    #
    # print(np.sum(Y_upsampled, axis = 0))

    graphs_upsampled, genders_upsampled, inss_upsampled, ages_upsampled, Y_upsampled = \
        shuffle(graphs_upsampled, genders_upsampled, inss_upsampled, ages_upsampled, Y_upsampled)
    return graphs_upsampled, genders_upsampled, inss_upsampled, ages_upsampled, Y_upsampled

def get_backbone_graph(graphs, threshold):
    """
    Get the backbone graph base on graphs from the training set
    """
    A, _ = graphs[:, 0, :, :], graphs[:, 1, :, :]
    A_mean = np.mean(A, axis = 0)
    A_backbone = A_mean.copy()
    A_backbone[A_mean > threshold] = 1.
    A_backbone[A_mean <= threshold] = 0.
    return A_backbone

def set_backbone_graph(graphs, A_backbone):
    _, X = graphs[:, 0, :, :], graphs[:, 1, :, :]
    # A_backbone = np.mean(A, axis = 0)
    N = X.shape[0]
    A = np.tile( A_backbone[np.newaxis, :, :], (N, 1, 1) )
    graphs[:, 0, :, :] = A
    return graphs

def convert_to_model_input(graphs):
    """
    Split input graph tensor into a tensor for A and another tensor for X
    """
    A, X = graphs[:, 0, :, :], graphs[:, 1, :, :]
    return A, X

def load_data(data_root_directory=DATA_dir, left_table_file=left_table_file, matrix_directory=matrices_dir):
    """
    Load data from files that are generated by converter.m
    data_root_directory: the root directory where all data files reside
    left_table_file: the file name of the left half of the original table
    matrix_directory: the directory which contains all csv files of matrices,
                file names are the Id entries of their corresponding rows
    """
    left_table = pd.read_csv(os.path.join(data_root_directory, left_table_file))
    print("Left table of shape", left_table.shape, "has been loaded!")
    print("Loading graphs...")
    matrices = []
    labels = []
    inss = []
    genders = []
    ages = []
    for row in tqdm(range(left_table.shape[0])):
        id = str(left_table.loc[row, 'Id'])
        # Read left table
        label_1hot = map_to_onehot(left_table.loc[row, 'label'], LABEL_LIST)
        if label_1hot[0] == 1:
            label_1hot = [1, 0]
        else:
            label_1hot = [0, 1]
        labels.append(label_1hot)
        inss.append(map_to_onehot(left_table.loc[row, 'Ins'], INS_LIST))
        genders.append(map_to_onehot(left_table.loc[row, 'Gender'], GENDER_LIST))
        ages.append(float(left_table.loc[row, 'Age']))
        # Read adjacency matrix
        mtx_path = os.path.join(data_root_directory, matrix_directory, id + ".csv")
        A = np.loadtxt(open(os.path.join(data_root_directory, matrix_directory, id + ".csv"), "r"), delimiter=",", skiprows=0)
        matrices.append(preprocess(A, weight_threshold))

    input_graphs = np.array(matrices)
    input_genders = np.array(genders)
    input_inss = np.array(inss)
    input_ages = np.array(ages)
    input_ages /= 100.
    input_Y = np.array(labels)

    input_graphs, input_genders, input_inss, input_ages, input_Y = shuffle(input_graphs, input_genders, input_inss, input_ages, input_Y)

    train_graphs, val_graphs, test_graphs = \
                    input_graphs[:train_size, :, :], \
                    input_graphs[train_size:train_size + val_size, :, :], \
                    input_graphs[train_size + val_size:, :, :]

    train_genders, val_genders, test_genders = \
                    input_genders[:train_size, :], \
                    input_genders[train_size:train_size + val_size, :], \
                    input_genders[train_size + val_size:, :]

    train_inss, val_inss, test_inss = \
                    input_inss[:train_size, :], \
                    input_inss[train_size:train_size + val_size, :], \
                    input_inss[train_size + val_size:, :]

    train_ages, val_ages, test_ages = \
                    input_ages[:train_size], \
                    input_ages[train_size:train_size + val_size], \
                    input_ages[train_size + val_size:]

    train_Y, val_Y, test_Y = \
                    input_Y[:train_size, :], \
                    input_Y[train_size:train_size + val_size, :], \
                    input_Y[train_size + val_size:, :]

    return  train_graphs, val_graphs, test_graphs, \
            train_genders, val_genders, test_genders, \
            train_inss, val_inss, test_inss, \
            train_ages, val_ages, test_ages, \
            train_Y, val_Y, test_Y


if __name__ == '__main__':

    train_graphs, val_graphs, test_graphs, \
            train_genders, val_genders, test_genders, \
            train_inss, val_inss, test_inss, \
            train_ages, val_ages, test_ages, \
            train_Y, val_Y, test_Y = load_data()
    A_backbone = get_backbone_graph(train_graphs, weight_threshold)
    train_graphs = set_backbone_graph(train_graphs, A_backbone)
    val_graphs = set_backbone_graph(val_graphs, A_backbone)
    test_graphs = set_backbone_graph(test_graphs, A_backbone)

    datasets = train_graphs, val_graphs, test_graphs, \
            train_genders, val_genders, test_genders, \
            train_inss, val_inss, test_inss, \
            train_ages, val_ages, test_ages, \
            train_Y, val_Y, test_Y

    pickle.dump( datasets, open( pickle_path, "wb" ) )

    train_graphs, val_graphs, test_graphs, \
            train_genders, val_genders, test_genders, \
            train_inss, val_inss, test_inss, \
            train_ages, val_ages, test_ages, \
            train_Y, val_Y, test_Y = pickle.load( open( pickle_path, "rb" ) )
    print("[Training]   Graph shape, Gender shape, Ins shape, Ages shape, Y shape: \n\t", \
        train_graphs.shape, train_genders.shape, train_inss.shape, train_ages.shape, train_Y.shape)
    print("[Validation] Graph shape, Gender shape, Ins shape, Ages shape, Y shape: \n\t", \
        val_graphs.shape, val_genders.shape, val_inss.shape, val_ages.shape, val_Y.shape)
    print("[Test]       Graph shape, Gender shape, Ins shape, Ages shape, Y shape: \n\t", \
        test_graphs.shape, test_genders.shape, test_inss.shape, test_ages.shape, test_Y.shape)

    print("[Training]   Class distribution", np.sum(train_Y, axis = 0))
    print("[Validation] Class distribution", np.sum(val_Y, axis = 0))
    print("[Test]       Class distribution", np.sum(test_Y, axis = 0))

    # ===================== UPSAMPLE =====================
    print("Upsampling datasets...")
    train_graphs, train_genders, train_inss, train_ages, train_Y = \
        upsample(train_graphs, train_genders, train_inss, train_ages, train_Y)

    val_graphs, val_genders, val_inss, val_ages, val_Y = \
        upsample(val_graphs, val_genders, val_inss, val_ages, val_Y)

    test_graphs, test_genders, test_inss, test_ages, test_Y = \
        upsample(test_graphs, test_genders, test_inss, test_ages, test_Y)

    upsampled_data = train_graphs, val_graphs, test_graphs, \
            train_genders, val_genders, test_genders, \
            train_inss, val_inss, test_inss, \
            train_ages, val_ages, test_ages, \
            train_Y, val_Y, test_Y

    pickle.dump(upsampled_data, open(upsampled_pickle_path, "wb"))

    train_graphs, val_graphs, test_graphs, \
            train_genders, val_genders, test_genders, \
            train_inss, val_inss, test_inss, \
            train_ages, val_ages, test_ages, \
            train_Y, val_Y, test_Y = pickle.load( open( upsampled_pickle_path, "rb" ) )

    print("[Training]   Upsampled class distribution", np.sum(train_Y, axis = 0))
    print("[Validation] Upsampled class distribution", np.sum(val_Y, axis = 0))
    print("[Test]       Upsampled class distribution", np.sum(test_Y, axis = 0))
