import os, sys
from tqdm import tqdm
import pickle
import json
import pandas as pd
import numpy as np
from sklearn.utils import shuffle
from config import *
from data import *


def load_raw_data(data_root_directory=DATA_dir, left_table_file=left_table_file, matrix_directory=matrices_dir):
    """
    Load data from files that are generated by converter.m
    data_root_directory: the root directory where all data files reside
    left_table_file: the file name of the left half of the original table
    matrix_directory: the directory which contains all csv files of matrices,
                file names are the Id entries of their corresponding rows
    """
    left_table = pd.read_csv(os.path.join(data_root_directory, left_table_file))
    print("Left table of shape", left_table.shape, "has been loaded!")
    print("Loading graphs...")
    matrices = []
    labels = []
    inss = []
    genders = []
    ages = []
    ids = []
    for row in tqdm(range(left_table.shape[0])):
        id = str(left_table.loc[row, 'Id'])
        ids.append(id)
        # Read left table
        label_1hot = map_to_onehot(left_table.loc[row, 'label'], LABEL_LIST)
        if label_1hot[0] == 1:
            label_1hot = [1, 0]
        else:
            label_1hot = [0, 1]
        labels.append(label_1hot)
        inss.append(map_to_onehot(left_table.loc[row, 'Ins'], INS_LIST))
        genders.append(map_to_onehot(left_table.loc[row, 'Gender'], GENDER_LIST))
        ages.append(float(left_table.loc[row, 'Age']))
        # Read adjacency matrix
        mtx_path = os.path.join(data_root_directory, matrix_directory, id + ".csv")
        A = np.loadtxt(open(os.path.join(data_root_directory, matrix_directory, id + ".csv"), "r"), delimiter=",", skiprows=0)
        matrices.append(A)

    input_ids = np.array(ids)
    input_graphs = np.array(matrices)
    input_genders = np.array(genders)
    input_inss = np.array(inss)
    input_ages = np.array(ages)
    input_ages /= 100.
    input_Y = np.array(labels)

    return input_ids, input_graphs, input_genders, input_inss, input_ages, input_Y

def recover_ids(set, input_set, input_ids):
    found_ids = []
    for i in tqdm(range(set.shape[0])):
        diff = np.abs(input_set - set[i, 1, :, :])
        total_diff = np.sum(np.sum(diff, axis = 1), axis = 1)
        match_idx = np.argmin(total_diff)

        id = input_ids[match_idx]
        if total_diff[total_diff == 0].shape[0] != 1:
            print("Multiple matches!!!!!")
            return None
        if id in found_ids:
            print("Duplicate id!!!!!")
            return None
        else:
            found_ids.append(id)
    return found_ids


if __name__ == '__main__':

    input_ids, input_graphs, input_genders, input_inss, input_ages, input_Y = load_raw_data()

    train_graphs, val_graphs, test_graphs, \
            train_genders, val_genders, test_genders, \
            train_inss, val_inss, test_inss, \
            train_ages, val_ages, test_ages, \
            train_Y, val_Y, test_Y = pickle.load( open( pickle_path, "rb" ) )

    split_ids = {}
    split_ids['train'] = recover_ids(train_graphs, input_graphs, input_ids)
    split_ids['val']   = recover_ids(val_graphs, input_graphs, input_ids)
    split_ids['test']  = recover_ids(test_graphs, input_graphs, input_ids)

    json = json.dumps(split_ids)
    with open(json_path, "w") as file:
        file.write(json)
